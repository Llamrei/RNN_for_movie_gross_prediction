{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Follows https://www.tensorflow.org/tutorials/text/text_classification_rnn\n",
    "\"\"\"\n",
    "import pickle as pkl\n",
    "import numpy as np\n",
    "import random\n",
    "import re\n",
    "\n",
    "import tensorflow_datasets as tfds\n",
    "import tensorflow as tf\n",
    "\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "datetime.datetime(2020, 12, 16, 15, 38, 11, 490947)"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from datetime import datetime\n",
    "datetime.now()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_graphs(history, metric):\n",
    "    plt.plot(history.history[metric])\n",
    "    plt.plot(history.history[\"val_\" + metric], \"\")\n",
    "    plt.xlabel(\"Epochs\")\n",
    "    plt.ylabel(metric)\n",
    "    plt.legend([metric, \"val_\" + metric])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def split_data_into_input_and_output(data):\n",
    "    \"\"\"Take given data of format from scraper [link] and return the inputs and outputs seperated.\n",
    "\n",
    "    Args:\n",
    "        data (list): A numpy array/list of named tuples which contains entries for 'gross',\n",
    "        'title', 'synopsis' and 'year'.\n",
    "    \"\"\"\n",
    "    data_in, data_out = list(zip(*[((x[\"synopsis\"]), x[\"gross\"]) for x in data]))\n",
    "    return np.array(data_in), np.array(data_out)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def add_signal(data):\n",
    "    \"\"\"\n",
    "    If the given data has no signal we cant fit a NN to it. As such, here we append how much the film grossed\n",
    "    into the synopsis of each title.\n",
    "\n",
    "    Args:\n",
    "        data (list): A numpy array/list of named tuples which contains entries for 'gross',\n",
    "        'title', 'synopsis' and 'year'.\n",
    "    \"\"\"\n",
    "    for row in data:\n",
    "        row[\"synopsis\"] = row[\"synopsis\"] + f' The film grossed ${row[\"gross\"]}'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "real_data = pkl.load(open(\"complete10000_films_and_synopsis.pickle\", \"rb\"))\n",
    "# Small sample size to really overfit the network\n",
    "data = real_data[:1000]\n",
    "# No extra signal added to inputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fraction of overall data\n",
    "training_fraction = 0.85\n",
    "# Fraction of training data\n",
    "validation_fraction = 0.2\n",
    "\n",
    "train_end = int(len(data) * training_fraction)\n",
    "train_data_in, train_data_out = split_data_into_input_and_output(data[:train_end])\n",
    "test_data_in, test_data_out = split_data_into_input_and_output(data[train_end:])\n",
    "\n",
    "train_dataset = tf.data.Dataset.from_tensor_slices((train_data_in, train_data_out))\n",
    "test_dataset = tf.data.Dataset.from_tensor_slices((test_data_in, test_data_out))\n",
    "\n",
    "\n",
    "# How much it loads into memory for sampling\n",
    "BUFFER_SIZE = 10000\n",
    "# Batch for gradient averaging\n",
    "BATCH_SIZE = 64\n",
    "# prefetch parrallelising loading + execution (not huge so not necessary)\n",
    "\n",
    "train_dataset = train_dataset.shuffle(BUFFER_SIZE).batch(BATCH_SIZE).prefetch(5)\n",
    "test_dataset = test_dataset.batch(BATCH_SIZE).prefetch(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "sample, label = next(iter(train_dataset.take(1)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "VOCAB_SIZE = 10000\n",
    "# Bigrams\n",
    "encoder = tf.keras.layers.experimental.preprocessing.TextVectorization(\n",
    "    max_tokens=VOCAB_SIZE, ngrams=2\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "encoder.adapt(train_dataset.map(lambda text, label: text))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[  18 1743 3843   11 3452   15    2  283 1122 1197 2031   16   11  165\n",
      "     4 8666    7   96   36   22    2 1019  947    4  801 4819 3182    1\n",
      "     1 3451   67 1348    1    1    1    1  209  451  211 5858 8665 1181\n",
      "     1 1153   82 4077 5702 3922 1026    0    0    0    0    0    0    0\n",
      "     0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "     0    0    0    0    0    0    0    0    0    0    0]\n",
      " [   3   48  256  217 2081    8    3  492  761   25   70  342 3396   14\n",
      "     3    1    6    2  918 4838 7459    1  240    1   12  339   15 3091\n",
      "     3  577   74 2411 2277    1 7629    1   31 1037 1378 4852 1653 8324\n",
      "  9305    1  107 6784    1   26 1346    1 4837 7458    1 8255    1    1\n",
      "  2711    1    1 1491  928    0    0    0    0    0    0    0    0    0\n",
      "     0    0    0    0    0    0    0    0    0    0    0]\n",
      " [  94  321 1247    9    2   84  733 1588 1525 5046 7765  260 1144  948\n",
      "  2533 1074    5 1549    1 6072 4421    1   47  142    1    1 8651 7431\n",
      "  5045 7764 5231 1143    1 7025 2620    1 8059    0    0    0    0    0\n",
      "     0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "     0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "     0    0    0    0    0    0    0    0    0    0    0]]\n"
     ]
    }
   ],
   "source": [
    "encoded_sample = encoder(sample).numpy()[:3]\n",
    "print(encoded_sample)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original:  b'When Jason Bourne is framed for a CIA operation gone awry, he is forced to resume his former life as a trained assassin to survive.'\n",
      "Round-trip:  when jason bourne is framed for a cia operation gone awry he is forced to resume his former life as a trained assassin to survive when jason jason bourne [UNK] [UNK] framed for for a a cia [UNK] [UNK] [UNK] [UNK] he is is forced forced to to resume resume his his former [UNK] life as as a a trained trained assassin assassin to to survive                                \n",
      "\n",
      "Original:  b'The two best special agents in the Wild West must save President Grant from the clutches of a diabolical, wheelchair-bound, steampunk-savvy, Confederate scientist bent on revenge for losing the Civil War.'\n",
      "Round-trip:  the two best special agents in the wild west must save president grant from the [UNK] of a diabolical wheelchairbound steampunksavvy [UNK] scientist [UNK] on revenge for losing the civil war the two two best [UNK] special agents [UNK] in the the wild wild west west must must save save president president grant [UNK] from the the clutches [UNK] of a a diabolical [UNK] wheelchairbound steampunksavvy steampunksavvy confederate [UNK] scientist bent [UNK] [UNK] revenge for [UNK] [UNK] the civil civil war                    \n",
      "\n",
      "Original:  b'Three women, detectives with a mysterious boss, retrieve stolen voice-ID software, using martial arts, tech skills, and sex appeal.'\n",
      "Round-trip:  three women detectives with a mysterious boss retrieve stolen voiceid software using martial arts tech skills and sex [UNK] three women women detectives [UNK] with a a mysterious [UNK] [UNK] retrieve stolen stolen voiceid voiceid software software using using martial martial arts [UNK] tech skills skills and [UNK] sex appeal                                            \n",
      "\n"
     ]
    }
   ],
   "source": [
    "vocab = np.array(encoder.get_vocabulary())\n",
    "\n",
    "for n in range(3):\n",
    "  print(\"Original: \", sample[n].numpy())\n",
    "  print(\"Round-trip: \", \" \".join(vocab[encoded_sample[n]]))\n",
    "  print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = tf.keras.Sequential(\n",
    "    [\n",
    "        encoder,\n",
    "        tf.keras.layers.Embedding(\n",
    "            input_dim=len(encoder.get_vocabulary()), output_dim=64, mask_zero=True\n",
    "        ),\n",
    "        tf.keras.layers.Bidirectional(tf.keras.layers.LSTM(64)),\n",
    "        tf.keras.layers.Dense(64, activation=\"relu\"),\n",
    "        tf.keras.layers.Dense(1),\n",
    "    ]\n",
    ")\n",
    "\n",
    "model.compile(\n",
    "    loss=tf.keras.losses.MeanSquaredError(),\n",
    "    optimizer=tf.keras.optimizers.Adam(),\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "14/14 [==============================] - 1s 101ms/step - loss: 41367767785406464.0000\n",
      "Epoch 2/10\n",
      "14/14 [==============================] - 1s 98ms/step - loss: 41367763490439168.0000\n",
      "Epoch 3/10\n",
      "14/14 [==============================] - 1s 97ms/step - loss: 41367754900504576.0000\n",
      "Epoch 4/10\n",
      "14/14 [==============================] - 1s 99ms/step - loss: 41367742015602688.0000\n",
      "Epoch 5/10\n",
      "14/14 [==============================] - 1s 98ms/step - loss: 41367729130700800.0000\n",
      "Epoch 6/10\n",
      "14/14 [==============================] - 1s 98ms/step - loss: 41367724835733504.0000\n",
      "Epoch 7/10\n",
      "14/14 [==============================] - 1s 99ms/step - loss: 41367716245798912.0000\n",
      "Epoch 8/10\n",
      "14/14 [==============================] - 1s 97ms/step - loss: 41367703360897024.0000\n",
      "Epoch 9/10\n",
      "14/14 [==============================] - 1s 98ms/step - loss: 41367690475995136.0000\n",
      "Epoch 10/10\n",
      "14/14 [==============================] - 1s 98ms/step - loss: 41367673296125952.0000\n"
     ]
    }
   ],
   "source": [
    "history = model.fit(\n",
    "    train_dataset, epochs=10\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3/3 [==============================] - 0s 19ms/step - loss: 7084215694786560.0000\n"
     ]
    }
   ],
   "source": [
    "res = model.evaluate(test_dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "289\n"
     ]
    }
   ],
   "source": [
    "sample_text = \"As a new threat to the galaxy rises, Rey, a desert scavenger, and Finn, an ex-stormtrooper, must join Han Solo and Chewbacca to search for the one hope of restoring peace.\"\n",
    "pred1 = model.predict(np.array([sample_text]))\n",
    "print(int(pred1[0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "289\n"
     ]
    }
   ],
   "source": [
    "non_existant_film = \"Este is a friend of mine we meet up every tuesday night for dinner and a glass of wine. She thinks he did it but just cant prove it\"\n",
    "pred2 = model.predict(np.array([non_existant_film]))\n",
    "print(int(pred2[0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "test_predictions = model.predict(test_data_in)\n",
    "train_predictions = model.predict(train_data_in)\n",
    "plt.scatter(test_data_out, test_predictions, label='test')\n",
    "plt.scatter(train_data_out, train_predictions, label='train')\n",
    "plt.legend()\n",
    "plt.xlabel('Truth')\n",
    "plt.ylabel('Prediction')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python3.8 | Tensorflow 2",
   "language": "python",
   "name": "tf2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
