{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "import random"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "datetime.datetime(2021, 1, 5, 17, 34, 29, 859321)"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from datetime import datetime\n",
    "datetime.now()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = np.array([(x,str(x)) for x in np.arange(10e5)],dtype=[('label','int32'),('input', 'U10')])\n",
    "np.random.shuffle(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "training_fraction = 0.85\n",
    "train_end = int(len(data) * training_fraction)\n",
    "\n",
    "labels, inputs = zip(*data)\n",
    "train_labels, train_inputs = np.array(labels[:train_end]), np.array(inputs[:train_end])\n",
    "test_labels, test_inputs = np.array(labels[train_end:]), np.array(inputs[train_end:])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(array([], dtype=int64),)\n",
      "(array([], dtype=int64),)\n"
     ]
    }
   ],
   "source": [
    "print(np.where(train_labels == 0.0))\n",
    "print(np.where(train_inputs == '0.0'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataset = tf.data.Dataset.from_tensor_slices((train_inputs, train_labels))\n",
    "test_dataset = tf.data.Dataset.from_tensor_slices((test_inputs, test_labels))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<TakeDataset shapes: ((), ()), types: (tf.string, tf.int32)>"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_dataset.take(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# How much it loads into memory for sampling\n",
    "BUFFER_SIZE = 100000\n",
    "# Batch for gradient averaging\n",
    "BATCH_SIZE = 64\n",
    "# prefetch parrallelising loading + execution (not huge so not necessary)\n",
    "\n",
    "train_dataset = train_dataset.shuffle(BUFFER_SIZE).batch(BATCH_SIZE).prefetch(BATCH_SIZE*2)\n",
    "test_dataset = test_dataset.batch(BATCH_SIZE).prefetch(BATCH_SIZE*2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tf.Tensor(\n",
      "[b'427973.0' b'478331.0' b'417521.0' b'73951.0' b'18784.0' b'27280.0'\n",
      " b'806339.0' b'651322.0' b'419850.0' b'56585.0' b'25182.0' b'512466.0'\n",
      " b'2606.0' b'106428.0' b'390431.0' b'124802.0' b'45026.0' b'745485.0'\n",
      " b'555457.0' b'673331.0' b'247627.0' b'453826.0' b'77916.0' b'560558.0'\n",
      " b'748156.0' b'413292.0' b'681367.0' b'830974.0' b'289767.0' b'659475.0'\n",
      " b'366807.0' b'192804.0' b'180115.0' b'774274.0' b'20257.0' b'504850.0'\n",
      " b'18695.0' b'821506.0' b'766839.0' b'560016.0' b'367098.0' b'40062.0'\n",
      " b'605977.0' b'320166.0' b'32677.0' b'823291.0' b'881591.0' b'159.0'\n",
      " b'812290.0' b'237645.0' b'243848.0' b'14616.0' b'982153.0' b'25481.0'\n",
      " b'921283.0' b'343517.0' b'295695.0' b'861066.0' b'797402.0' b'592360.0'\n",
      " b'866738.0' b'996210.0' b'972485.0' b'839795.0'], shape=(64,), dtype=string) tf.Tensor(\n",
      "[427973 478331 417521  73951  18784  27280 806339 651322 419850  56585\n",
      "  25182 512466   2606 106428 390431 124802  45026 745485 555457 673331\n",
      " 247627 453826  77916 560558 748156 413292 681367 830974 289767 659475\n",
      " 366807 192804 180115 774274  20257 504850  18695 821506 766839 560016\n",
      " 367098  40062 605977 320166  32677 823291 881591    159 812290 237645\n",
      " 243848  14616 982153  25481 921283 343517 295695 861066 797402 592360\n",
      " 866738 996210 972485 839795], shape=(64,), dtype=int32)\n"
     ]
    }
   ],
   "source": [
    "sample, label = next(iter(train_dataset.take(1)))\n",
    "print(sample, label)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def standardize(batch):\n",
    "    '''\n",
    "    Designed to seperate digits in number\n",
    "    '''\n",
    "    DEFAULT_REGEX = r'[!\"#$%&()\\*\\+,-\\./:;<=>?@\\[\\\\\\]^_`{|}~\\']'\n",
    "    # Remove any pennies/cents\n",
    "    batch = tf.strings.regex_replace(batch, r'([\\.|,][0-9].*)', '')\n",
    "    # Normal punc strip\n",
    "    batch = tf.strings.regex_replace(batch, DEFAULT_REGEX, \"\")\n",
    "    # Spread out the values so we can get them frequent enough to appear in our vocab\n",
    "    batch = tf.strings.regex_replace(batch, r'([0-9])', r'\\1 ')\n",
    "    return batch\n",
    "\n",
    "VOCAB_SIZE = 10000\n",
    "encoder = tf.keras.layers.experimental.preprocessing.TextVectorization(\n",
    "    max_tokens=VOCAB_SIZE, standardize=standardize, ngrams=(1,)\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "encoder.adapt(train_dataset.map(lambda text, label: text))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[3 2 5 9 5 6]\n",
      " [3 5 4 6 6 8]\n",
      " [3 8 5 7 2 8]]\n"
     ]
    }
   ],
   "source": [
    "encoded_sample = encoder(sample).numpy()[:3]\n",
    "print(encoded_sample)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original:  b'427973.0'\n",
      "Round-trip:  4 2 7 9 7 3\n",
      "\n",
      "Original:  b'478331.0'\n",
      "Round-trip:  4 7 8 3 3 1\n",
      "\n",
      "Original:  b'417521.0'\n",
      "Round-trip:  4 1 7 5 2 1\n",
      "\n"
     ]
    }
   ],
   "source": [
    "vocab = np.array(encoder.get_vocabulary())\n",
    "for n in range(3):\n",
    "  print(\"Original: \", sample[n].numpy())\n",
    "  print(\"Round-trip: \", \" \".join(vocab[encoded_sample[n]]))\n",
    "  print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = tf.keras.Sequential(\n",
    "    [\n",
    "        encoder,\n",
    "        tf.keras.layers.Embedding(\n",
    "            input_dim=len(encoder.get_vocabulary()), output_dim=64, mask_zero=True\n",
    "        ),\n",
    "        tf.keras.layers.Bidirectional(tf.keras.layers.LSTM(64)),\n",
    "        tf.keras.layers.Dense(64, activation=\"relu\"),\n",
    "        tf.keras.layers.Dense(64, activation=\"relu\"),\n",
    "        tf.keras.layers.Dense(1),\n",
    "    ]\n",
    ")\n",
    "\n",
    "model.compile(\n",
    "    loss=tf.keras.losses.MeanSquaredError(),\n",
    "    optimizer=tf.keras.optimizers.Adam(),\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "13282/13282 [==============================] - 138s 10ms/step - loss: 18529572864.0000 - val_loss: 4372149.0000\n",
      "Epoch 2/100\n",
      "13282/13282 [==============================] - 133s 10ms/step - loss: 3338156.2500 - val_loss: 8879116.0000\n",
      "Epoch 3/100\n",
      "13282/13282 [==============================] - 132s 10ms/step - loss: 1549212.0000 - val_loss: 529504.8750\n",
      "Epoch 4/100\n",
      "13282/13282 [==============================] - 131s 10ms/step - loss: 1029516.7500 - val_loss: 203001.4062\n",
      "Epoch 5/100\n",
      "13282/13282 [==============================] - 130s 10ms/step - loss: 772689.6875 - val_loss: 468988.8125\n",
      "Epoch 6/100\n",
      "13282/13282 [==============================] - 130s 10ms/step - loss: 590237.7500 - val_loss: 1720460.7500\n",
      "Epoch 7/100\n",
      "11385/13282 [========================>.....] - ETA: 18s - loss: 466200.2188"
     ]
    }
   ],
   "source": [
    "history = model.fit(\n",
    "    train_dataset, epochs=100, validation_steps=30, validation_data=test_dataset\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "res = model.evaluate(test_dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "def plot_graphs(history, metric):\n",
    "    plt.plot(history.history[metric])\n",
    "    plt.plot(history.history[\"val_\" + metric], \"\")\n",
    "    plt.xlabel(\"Epochs\")\n",
    "    plt.ylabel(metric)\n",
    "    plt.legend([metric, \"val_\" + metric])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_graphs(history,'loss')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_predictions = model.predict(test_inputs)\n",
    "train_predictions = model.predict(train_inputs)\n",
    "plt.scatter(train_labels, train_predictions, label='train', s=2)\n",
    "plt.scatter(test_labels, test_predictions, label='test', s=2)\n",
    "plt.legend()\n",
    "plt.xlabel('Truth')\n",
    "plt.ylabel('Prediction')\n",
    "plt.savefig('digits_unigrams.png')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python3.8 | Tensorflow 2",
   "language": "python",
   "name": "tf2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
