{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "import random"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = np.array([(x,str(x)) for x in np.arange(10e5)],dtype=[('label','int32'),('input', 'U10')])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "training_fraction = 0.85\n",
    "train_end = int(len(data) * training_fraction)\n",
    "\n",
    "labels, inputs = zip(*data)\n",
    "train_labels, train_inputs = np.array(labels[:train_end]), np.array(inputs[:train_end])\n",
    "test_labels, test_inputs = np.array(labels[train_end:]), np.array(inputs[train_end:])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(array([0]),)\n",
      "(array([0]),)\n",
      "(array([], dtype=int64),)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-30-416eb805b2e6>:3: FutureWarning: elementwise == comparison failed and returning scalar instead; this will raise an error or perform elementwise comparison in the future.\n",
      "  print(np.where(data == (0.0,'0.0')))\n"
     ]
    }
   ],
   "source": [
    "print(np.where(train_labels == 0.0))\n",
    "print(np.where(train_inputs == '0.0'))\n",
    "print(np.where(data == (0.0,'0.0')))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataset = tf.data.Dataset.from_tensor_slices((train_inputs, train_labels))\n",
    "test_dataset = tf.data.Dataset.from_tensor_slices((test_inputs, test_labels))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<TakeDataset shapes: ((), ()), types: (tf.string, tf.int32)>"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_dataset.take(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "# How much it loads into memory for sampling\n",
    "BUFFER_SIZE = 100000\n",
    "# Batch for gradient averaging\n",
    "BATCH_SIZE = 64\n",
    "# prefetch parrallelising loading + execution (not huge so not necessary)\n",
    "\n",
    "train_dataset = train_dataset.shuffle(BUFFER_SIZE).batch(BATCH_SIZE).prefetch(BATCH_SIZE*2)\n",
    "test_dataset = test_dataset.batch(BATCH_SIZE).prefetch(BATCH_SIZE*2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tf.Tensor(\n",
      "[b'79355.0' b'46193.0' b'49303.0' b'63600.0' b'27182.0' b'12455.0'\n",
      " b'1300.0' b'20993.0' b'67096.0' b'73306.0' b'43535.0' b'27926.0'\n",
      " b'94576.0' b'65195.0' b'29584.0' b'15386.0' b'58952.0' b'51546.0'\n",
      " b'93976.0' b'89059.0' b'97591.0' b'40263.0' b'50895.0' b'80269.0'\n",
      " b'76194.0' b'41752.0' b'43663.0' b'75615.0' b'94185.0' b'9782.0'\n",
      " b'90570.0' b'8051.0' b'80433.0' b'16938.0' b'17964.0' b'41786.0'\n",
      " b'30596.0' b'89461.0' b'34655.0' b'82285.0' b'97534.0' b'16609.0'\n",
      " b'51878.0' b'56155.0' b'39104.0' b'96685.0' b'20444.0' b'7612.0'\n",
      " b'91508.0' b'23128.0' b'72313.0' b'43525.0' b'57920.0' b'99315.0'\n",
      " b'6761.0' b'98183.0' b'25447.0' b'26263.0' b'41064.0' b'93616.0'\n",
      " b'59610.0' b'36805.0' b'65623.0' b'60591.0'], shape=(64,), dtype=string) tf.Tensor(\n",
      "[79355 46193 49303 63600 27182 12455  1300 20993 67096 73306 43535 27926\n",
      " 94576 65195 29584 15386 58952 51546 93976 89059 97591 40263 50895 80269\n",
      " 76194 41752 43663 75615 94185  9782 90570  8051 80433 16938 17964 41786\n",
      " 30596 89461 34655 82285 97534 16609 51878 56155 39104 96685 20444  7612\n",
      " 91508 23128 72313 43525 57920 99315  6761 98183 25447 26263 41064 93616\n",
      " 59610 36805 65623 60591], shape=(64,), dtype=int32)\n"
     ]
    }
   ],
   "source": [
    "sample, label = next(iter(train_dataset.take(1)))\n",
    "print(sample, label)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "def standardize(batch):\n",
    "    '''\n",
    "    Designed to seperate digits in number\n",
    "    '''\n",
    "    DEFAULT_REGEX = r'[!\"#$%&()\\*\\+,-\\./:;<=>?@\\[\\\\\\]^_`{|}~\\']'\n",
    "    # Remove any pennies/cents\n",
    "    batch = tf.strings.regex_replace(batch, r'([\\.|,][0-9].*)', '')\n",
    "    # Normal punc strip\n",
    "    batch = tf.strings.regex_replace(batch, DEFAULT_REGEX, \"\")\n",
    "    # Spread out the values so we can get them frequent enough to appear in our vocab\n",
    "    batch = tf.strings.regex_replace(batch, r'([0-9])', r'\\1 ')\n",
    "    return batch\n",
    "\n",
    "VOCAB_SIZE = 10000\n",
    "encoder = tf.keras.layers.experimental.preprocessing.TextVectorization(\n",
    "    max_tokens=VOCAB_SIZE, standardize=standardize, ngrams=(1,)\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "encoder.adapt(train_dataset.map(lambda text, label: text))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 6 10  3  8  8]\n",
      " [ 2  7  5 10  3]\n",
      " [ 2 10  3 11  3]]\n"
     ]
    }
   ],
   "source": [
    "encoded_sample = encoder(sample).numpy()[:3]\n",
    "print(encoded_sample)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original:  b'79355.0'\n",
      "Round-trip:  7 9 3 5 5\n",
      "\n",
      "Original:  b'46193.0'\n",
      "Round-trip:  4 6 1 9 3\n",
      "\n",
      "Original:  b'49303.0'\n",
      "Round-trip:  4 9 3 0 3\n",
      "\n"
     ]
    }
   ],
   "source": [
    "vocab = np.array(encoder.get_vocabulary())\n",
    "for n in range(3):\n",
    "  print(\"Original: \", sample[n].numpy())\n",
    "  print(\"Round-trip: \", \" \".join(vocab[encoded_sample[n]]))\n",
    "  print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = tf.keras.Sequential(\n",
    "    [\n",
    "        encoder,\n",
    "        tf.keras.layers.Embedding(\n",
    "            input_dim=len(encoder.get_vocabulary()), output_dim=64, mask_zero=True\n",
    "        ),\n",
    "        tf.keras.layers.Bidirectional(tf.keras.layers.LSTM(64)),\n",
    "        tf.keras.layers.Dense(64, activation=\"relu\"),\n",
    "        tf.keras.layers.Dense(1),\n",
    "    ]\n",
    ")\n",
    "\n",
    "model.compile(\n",
    "    loss=tf.keras.losses.MeanSquaredError(),\n",
    "    optimizer=tf.keras.optimizers.Adam(),\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "13282/13282 [==============================] - 139s 10ms/step - loss: 7352290.0000 - val_loss: 19422340.0000\n"
     ]
    }
   ],
   "source": [
    "history = model.fit(\n",
    "    train_dataset, epochs=1, validation_steps=30, validation_data=test_dataset\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2344/2344 [==============================] - 9s 4ms/step - loss: 17154484224.0000\n"
     ]
    }
   ],
   "source": [
    "res = model.evaluate(test_dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n",
      "13282/13282 [==============================] - 145s 11ms/step - loss: 47187673088.0000 - val_loss: 70932611072.0000\n",
      "Epoch 2/50\n",
      "13282/13282 [==============================] - 140s 11ms/step - loss: 1471384448.0000 - val_loss: 76223144.0000\n",
      "Epoch 3/50\n",
      "11118/13282 [========================>.....] - ETA: 22s - loss: 36046752.0000"
     ]
    }
   ],
   "source": [
    "long_model = tf.keras.Sequential(\n",
    "    [\n",
    "        encoder,\n",
    "        tf.keras.layers.Embedding(\n",
    "            input_dim=len(encoder.get_vocabulary()), output_dim=64, mask_zero=True\n",
    "        ),\n",
    "        tf.keras.layers.Bidirectional(tf.keras.layers.LSTM(64)),\n",
    "        tf.keras.layers.Dense(64, activation=\"relu\"),\n",
    "        tf.keras.layers.Dense(1),\n",
    "    ]\n",
    ")\n",
    "\n",
    "long_model.compile(\n",
    "    loss=tf.keras.losses.MeanSquaredError(),\n",
    "    optimizer=tf.keras.optimizers.Adam(),\n",
    ")\n",
    "\n",
    "history = long_model.fit(\n",
    "    train_dataset, epochs=50, validation_steps=30, validation_data=test_dataset\n",
    ")\n",
    "\n",
    "long_res = long_model.evaluate(test_dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sample_text = '9001234761'\n",
    "predictions = model.predict(np.array([sample_text]))\n",
    "predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[238.6538]], dtype=float32)"
      ]
     },
     "execution_count": 70,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sample_text = 'asd'\n",
    "predictions = model.predict(np.array([sample_text]))\n",
    "predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "def plot_graphs(history, metric):\n",
    "    plt.plot(history.history[metric])\n",
    "    plt.plot(history.history[\"val_\" + metric], \"\")\n",
    "    plt.xlabel(\"Epochs\")\n",
    "    plt.ylabel(metric)\n",
    "    plt.legend([metric, \"val_\" + metric])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plot_graphs(history,'loss')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python3.8 | Tensorflow 2",
   "language": "python",
   "name": "tf2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
